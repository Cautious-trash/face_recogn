{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12345.png', '321653.png', '43562.png', '456214.png', '54362.png', '76543.png', '852741.png', '963852.png']\n",
      "['12345', '321653', '43562', '456214', '54362', '76543', '852741', '963852']\n",
      "Encoding Started ...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encodeList\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding Started ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m encodeListKnown \u001b[38;5;241m=\u001b[39m \u001b[43mfindEncodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgList\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m encodeListKnownWithIds \u001b[38;5;241m=\u001b[39m [encodeListKnown, studentIds]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding Complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 41\u001b[0m, in \u001b[0;36mfindEncodings\u001b[1;34m(imagesList)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imagesList:\n\u001b[0;32m     40\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 41\u001b[0m     encode \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     42\u001b[0m     encodeList\u001b[38;5;241m.\u001b[39mappend(encode)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encodeList\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import os\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "from firebase_admin import  storage\n",
    "\n",
    "cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': \"https://face-recognition-e9ea5-default-rtdb.asia-southeast1.firebasedatabase.app/\",\n",
    "    'storageBucket': \"face-recognition-e9ea5.appspot.com\"\n",
    "})\n",
    "\n",
    "# Importing student images\n",
    "folderPath = 'Images'\n",
    "pathList = os.listdir(folderPath)\n",
    "print(pathList)\n",
    "imgList = []\n",
    "studentIds = []\n",
    "for path in pathList:\n",
    "    imgList.append(cv2.imread(os.path.join(folderPath, path)))\n",
    "    studentIds.append(os.path.splitext(path)[0])\n",
    "\n",
    "    fileName = f'{folderPath}/{path}'\n",
    "    bucket = storage.bucket()\n",
    "    blob = bucket.blob(fileName)\n",
    "    blob.upload_from_filename(fileName)\n",
    "\n",
    "\n",
    "    # print(path)\n",
    "    # print(os.path.splitext(path)[0])\n",
    "print(studentIds)\n",
    "\n",
    "\n",
    "def findEncodings(imagesList):\n",
    "    encodeList = []\n",
    "    for img in imagesList:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "\n",
    "    return encodeList\n",
    "\n",
    "\n",
    "print(\"Encoding Started ...\")\n",
    "encodeListKnown = findEncodings(imgList)\n",
    "encodeListKnownWithIds = [encodeListKnown, studentIds]\n",
    "print(\"Encoding Complete\")\n",
    "\n",
    "file = open(\"EncodeFiles.p\", 'wb')\n",
    "pickle.dump(encodeListKnownWithIds, file)\n",
    "file.close()\n",
    "print(\"File Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Encode File ...\n",
      "Encode File Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import cvzone\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db, storage\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Firebase\n",
    "cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': \"https://face-recognition-e9ea5-default-rtdb.asia-southeast1.firebasedatabase.app/\",\n",
    "    'storageBucket': \"face-recognition-e9ea5.appspot.com\"\n",
    "})\n",
    "\n",
    "bucket = storage.bucket()\n",
    "\n",
    "# Setup webcam\n",
    "cap = cv2.VideoCapture(0)  # Changed to 0 for default webcam, ensure it's correct\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# Load background image\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "# Import mode images\n",
    "folderModePath = 'Resources/Modes'\n",
    "modePathList = os.listdir(folderModePath)\n",
    "imgModeList = [cv2.imread(os.path.join(folderModePath, path)) for path in modePathList]\n",
    "\n",
    "# Load the encoding file\n",
    "print(\"Loading Encode File ...\")\n",
    "with open('EncodeFiles.p', 'rb') as file:\n",
    "    encodeListKnownWithIds = pickle.load(file)\n",
    "encodeListKnown, studentIds = encodeListKnownWithIds\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = -1\n",
    "imgStudent = []\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "    \n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "\n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "    if faceCurFrame:\n",
    "        for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "            matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "            faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "\n",
    "            matchIndex = np.argmin(faceDis)\n",
    "            if matches[matchIndex]:\n",
    "                y1, x2, y2, x1 = [coord * 4 for coord in faceLoc]\n",
    "                bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "                imgBackground = cvzone.cornerRect(imgBackground, bbox, rt=0)\n",
    "                id = studentIds[matchIndex]\n",
    "                if counter == 0:\n",
    "                    cvzone.putTextRect(imgBackground, \"Loading\", (275, 400))\n",
    "                    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "                    cv2.waitKey(1)\n",
    "                    counter = 1\n",
    "                    modeType = 1\n",
    "\n",
    "        if counter != 0:\n",
    "            if counter == 1:\n",
    "                studentInfo = db.reference(f'Students/{id}').get()\n",
    "                if studentInfo:\n",
    "                    blob = bucket.get_blob(f'Images/{id}.png')\n",
    "                    if blob:\n",
    "                        array = np.frombuffer(blob.download_as_string(), np.uint8)\n",
    "                        imgStudent = cv2.imdecode(array, cv2.IMREAD_COLOR)\n",
    "                    \n",
    "                    lastAttendanceTime = studentInfo.get('last_attendance_time')\n",
    "                    if lastAttendanceTime:\n",
    "                        datetimeObject = datetime.strptime(lastAttendanceTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        secondsElapsed = (datetime.now() - datetimeObject).total_seconds()\n",
    "                        if secondsElapsed > 30:\n",
    "                            ref = db.reference(f'Students/{id}')\n",
    "                            studentInfo['total_attendance'] += 1\n",
    "                            ref.child('total_attendance').set(studentInfo['total_attendance'])\n",
    "                            ref.child('last_attendance_time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                        else:\n",
    "                            modeType = 3\n",
    "                            counter = 0\n",
    "                            imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "                    else:\n",
    "                        print(\"No last attendance time found for student ID:\", id)\n",
    "                else:\n",
    "                    print(\"No student info found for student ID:\", id)\n",
    "\n",
    "            if modeType != 3:\n",
    "                if 10 < counter < 20:\n",
    "                    modeType = 2\n",
    "\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "                if counter <= 10 and studentInfo:\n",
    "                    cv2.putText(imgBackground, str(studentInfo['total_attendance']), (861, 125),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['major']), (1006, 550),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(id), (1006, 493),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "                    (w, h), _ = cv2.getTextSize(studentInfo['name'], cv2.FONT_HERSHEY_COMPLEX, 1, 1)\n",
    "                    offset = (414 - w) // 2\n",
    "                    cv2.putText(imgBackground, str(studentInfo['name']), (808 + offset, 445),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 50), 1)\n",
    "\n",
    "                    imgBackground[175:175 + 216, 909:909 + 216] = imgStudent\n",
    "\n",
    "                counter += 1\n",
    "                if counter >= 20:\n",
    "                    counter = 0\n",
    "                    modeType = 0\n",
    "                    studentInfo = {}\n",
    "                    imgStudent = []\n",
    "                    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    else:\n",
    "        modeType = 0\n",
    "        counter = 0\n",
    "\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('y'):\n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "\n",
    "cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': \"https://face-recognition-e9ea5-default-rtdb.asia-southeast1.firebasedatabase.app/\"\n",
    "})\n",
    "\n",
    "ref = db.reference('students')\n",
    "\n",
    "data = {\n",
    "    \"321653\":\n",
    "        {\n",
    "            \"name\": \"Rishbah Jain\",\n",
    "            \"major\": \"Robotics\",\n",
    "            \"total_attendance\": 7,\n",
    "        },\n",
    "     \"76543\":\n",
    "        {\n",
    "            \"name\": \"sanjeev\",\n",
    "            \"major\": \"Robotics\",\n",
    "            \"total_attendance\": 1,\n",
    "        }, \n",
    "    \"12345\":\n",
    "        {\n",
    "            \"name\": \"saught\",\n",
    "            \"major\": \"Robotics\",\n",
    "            \"total_attendance\": 2,\n",
    "        },    \n",
    "    \"43562\":\n",
    "        {\n",
    "            \"name\": \"Nitin Rawat\",\n",
    "            \"major\": \"Machine Larning\",\n",
    "            \"total_attendance\": 7,\n",
    "        },   \n",
    "               \n",
    "    \"852741\":\n",
    "        {\n",
    "            \"name\": \"Emly Blunt\",\n",
    "            \"major\": \"Economics\",\n",
    "            \"total_attendance\": 12,\n",
    "        },\n",
    "    \"963852\":\n",
    "        {\n",
    "            \"name\": \"Elon Musk\",\n",
    "            \"major\": \"Physics\",  \n",
    "            \"total_attendance\": 7,\n",
    "        }\n",
    "}\n",
    "\n",
    "for key, value in data.items():\n",
    "    ref.child(key).set(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
